{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_data = h5py.File('C:/Users/Student/Desktop/Facial_Emotion_Detection/Ck+/Ck_data.h5', 'r', driver='core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.expand_dims(np.asarray(ck_data['data_pixel']), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.asarray(ck_data['data_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = to_categorical(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (784, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training: ',X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  (197, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Validation: ',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, Activation, BatchNormalization, MaxPooling2D, Dropout, Dense, Flatten, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(48,48,1)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 1), padding='same', input_shape=(48,48,1)))\n",
    "    model.add(Convolution2D(64, (1, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(128, (3, 1), padding='same'))\n",
    "    model.add(Convolution2D(128, (1, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(256, (3, 1), padding='same'))\n",
    "    model.add(Convolution2D(256, (1, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(512, (3, 1), padding='same'))\n",
    "    model.add(Convolution2D(512, (1, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = get_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = get_nn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        256       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        12352     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       24704     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       49280     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       98560     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 256)       196864    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 6, 6, 512)         393728    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 6, 512)         786944    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2359808   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,062,535\n",
      "Trainable params: 4,059,079\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               1180160   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,316,359\n",
      "Trainable params: 1,314,823\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, threshold_shift=0):\n",
    "    beta = 1\n",
    "\n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin), axis=1) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)), axis=1)\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = beta ** 2\n",
    "    return K.mean((beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_model(model):\n",
    "    filepath='../opt/ck-cnn/Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='auto')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', cooldown=0, min_lr=0)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,   # randomly flip images\n",
    "        )\n",
    "\n",
    "\n",
    "    datagen.fit(X_train)\n",
    "    datagen.fit(X_test)    \n",
    "    batch_size = 32\n",
    "\n",
    "    num_epochs = 25\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=[fbeta, 'acc'])\n",
    "    train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "    test_flow = datagen.flow(X_test, Y_test)\n",
    "    history = model.fit_generator(train_flow,\n",
    "                    steps_per_epoch=len(X_train) / batch_size,\n",
    "                    epochs=num_epochs, \n",
    "                    verbose=1, \n",
    "                    validation_data=test_flow, \n",
    "                    validation_steps=len(X_test) / batch_size,\n",
    "                    callbacks=[checkpointer, reduce_lr, checkpointer])\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(model):\n",
    "    filepath='../opt/ck-nn/Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='auto')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', cooldown=0, min_lr=0)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,   # randomly flip images\n",
    "        )\n",
    "\n",
    "\n",
    "    datagen.fit(X_train)\n",
    "    datagen.fit(X_test)    \n",
    "    batch_size = 32\n",
    "\n",
    "    num_epochs = 25\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=[fbeta, 'acc'])\n",
    "    train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "    test_flow = datagen.flow(X_test, Y_test)\n",
    "    history = model.fit_generator(train_flow,\n",
    "                    steps_per_epoch=len(X_train) / batch_size,\n",
    "                    epochs=num_epochs, \n",
    "                    verbose=1, \n",
    "                    validation_data=test_flow, \n",
    "                    validation_steps=len(X_test) / batch_size,\n",
    "                    callbacks=[checkpointer, reduce_lr, checkpointer])\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_6028\\1511627495.py:30: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_flow,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/24 [==============================] - ETA: 0s - loss: 1.7273 - fbeta: 0.2300 - acc: 0.3954\n",
      "Epoch 1: saving model to ../opt/ck-cnn\\Model.01-0.1980.hdf5\n",
      "\n",
      "Epoch 1: saving model to ../opt/ck-cnn\\Model.01-0.1980.hdf5\n",
      "24/24 [==============================] - 14s 478ms/step - loss: 1.7273 - fbeta: 0.2300 - acc: 0.3954 - val_loss: 16.0172 - val_fbeta: 0.1982 - val_acc: 0.1980 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 1.1264 - fbeta: 0.5288 - acc: 0.6084\n",
      "Epoch 2: saving model to ../opt/ck-cnn\\Model.02-0.5888.hdf5\n",
      "\n",
      "Epoch 2: saving model to ../opt/ck-cnn\\Model.02-0.5888.hdf5\n",
      "24/24 [==============================] - 11s 453ms/step - loss: 1.1264 - fbeta: 0.5288 - acc: 0.6084 - val_loss: 2.4403 - val_fbeta: 0.6143 - val_acc: 0.5888 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.7538 - fbeta: 0.6388 - acc: 0.7347\n",
      "Epoch 3: saving model to ../opt/ck-cnn\\Model.03-0.5888.hdf5\n",
      "\n",
      "Epoch 3: saving model to ../opt/ck-cnn\\Model.03-0.5888.hdf5\n",
      "24/24 [==============================] - 12s 484ms/step - loss: 0.7538 - fbeta: 0.6388 - acc: 0.7347 - val_loss: 2.1012 - val_fbeta: 0.5375 - val_acc: 0.5888 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.5739 - fbeta: 0.7250 - acc: 0.7793\n",
      "Epoch 4: saving model to ../opt/ck-cnn\\Model.04-0.7310.hdf5\n",
      "\n",
      "Epoch 4: saving model to ../opt/ck-cnn\\Model.04-0.7310.hdf5\n",
      "24/24 [==============================] - 12s 474ms/step - loss: 0.5739 - fbeta: 0.7250 - acc: 0.7793 - val_loss: 0.9431 - val_fbeta: 0.7170 - val_acc: 0.7310 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.4457 - fbeta: 0.8075 - acc: 0.8418\n",
      "Epoch 5: saving model to ../opt/ck-cnn\\Model.05-0.6244.hdf5\n",
      "\n",
      "Epoch 5: saving model to ../opt/ck-cnn\\Model.05-0.6244.hdf5\n",
      "24/24 [==============================] - 12s 473ms/step - loss: 0.4457 - fbeta: 0.8075 - acc: 0.8418 - val_loss: 1.9065 - val_fbeta: 0.6366 - val_acc: 0.6244 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.3102 - fbeta: 0.8650 - acc: 0.9031\n",
      "Epoch 6: saving model to ../opt/ck-cnn\\Model.06-0.8426.hdf5\n",
      "\n",
      "Epoch 6: saving model to ../opt/ck-cnn\\Model.06-0.8426.hdf5\n",
      "24/24 [==============================] - 12s 508ms/step - loss: 0.3102 - fbeta: 0.8650 - acc: 0.9031 - val_loss: 0.4533 - val_fbeta: 0.8330 - val_acc: 0.8426 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.2572 - fbeta: 0.8938 - acc: 0.9133\n",
      "Epoch 7: saving model to ../opt/ck-cnn\\Model.07-0.5990.hdf5\n",
      "\n",
      "Epoch 7: saving model to ../opt/ck-cnn\\Model.07-0.5990.hdf5\n",
      "24/24 [==============================] - 13s 525ms/step - loss: 0.2572 - fbeta: 0.8938 - acc: 0.9133 - val_loss: 1.3193 - val_fbeta: 0.5946 - val_acc: 0.5990 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.2390 - fbeta: 0.9000 - acc: 0.9273\n",
      "Epoch 8: saving model to ../opt/ck-cnn\\Model.08-0.8985.hdf5\n",
      "\n",
      "Epoch 8: saving model to ../opt/ck-cnn\\Model.08-0.8985.hdf5\n",
      "24/24 [==============================] - 13s 531ms/step - loss: 0.2390 - fbeta: 0.9000 - acc: 0.9273 - val_loss: 0.3021 - val_fbeta: 0.8884 - val_acc: 0.8985 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.1813 - fbeta: 0.9250 - acc: 0.9477\n",
      "Epoch 9: saving model to ../opt/ck-cnn\\Model.09-0.9188.hdf5\n",
      "\n",
      "Epoch 9: saving model to ../opt/ck-cnn\\Model.09-0.9188.hdf5\n",
      "24/24 [==============================] - 14s 558ms/step - loss: 0.1813 - fbeta: 0.9250 - acc: 0.9477 - val_loss: 0.3741 - val_fbeta: 0.9000 - val_acc: 0.9188 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "25/24 [==============================] - ETA: 0s - loss: 0.1671 - fbeta: 0.9438 - acc: 0.9528\n",
      "Epoch 10: saving model to ../opt/ck-cnn\\Model.10-0.8477.hdf5\n",
      "\n",
      "Epoch 10: saving model to ../opt/ck-cnn\\Model.10-0.8477.hdf5\n",
      "24/24 [==============================] - 13s 511ms/step - loss: 0.1671 - fbeta: 0.9438 - acc: 0.9528 - val_loss: 0.5891 - val_fbeta: 0.8661 - val_acc: 0.8477 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "11/24 [============>.................] - ETA: 6s - loss: 0.1570 - fbeta: 0.9403 - acc: 0.9432"
     ]
    }
   ],
   "source": [
    "cnn_model = train_cnn_model(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_history, nn_model = train_nn_model(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = Y_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=range(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(history, model):\n",
    "    batch_size = 32\n",
    "    score = model.evaluate(X_test, Y_test, steps=(int)(len(X_test) / batch_size))\n",
    "    print('Evaluation loss: ', score[0])\n",
    "    print('Evaluation accuracy: ', score[1])\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'], color='b', label='Training')\n",
    "    plt.plot(history.history['val_acc'], color='g', label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'], color='b', label='Training')\n",
    "    plt.plot(history.history['val_loss'], color='g', label='Validation')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.show()\n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    y_true = np.asarray([np.argmax(i) for i in Y_test])\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalised = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.set(font_scale=1.5) \n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = sns.heatmap(cm_normalised, annot=True, linewidths=0, square=False, \n",
    "                        cmap=\"Greens\", yticklabels=labels, xticklabels=labels, vmin=0, vmax=np.max(cm_normalised), \n",
    "                        fmt=\".2f\", annot_kws={\"size\": 20})\n",
    "    ax.set(xlabel='Predicted label', ylabel='True label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(history, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(nn_history, nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
